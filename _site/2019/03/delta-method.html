<!DOCTYPE html>

<html>

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>
        The Delta Method - A Rambling On
        
    </title>

    <meta name="description"
        content="Here, we’ll look at various applications of the Delta Method, especially in the context of variance stabilizing transformations, along with looking at the co...">

    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet'
        type='text/css'>
    <link
        href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800'
        rel='stylesheet' type='text/css'>

    <link rel="stylesheet" href="/assets/vendor/bootstrap/css/bootstrap.min.css">

    <link rel="stylesheet" href="/assets/vendor/fontawesome-free/css/all.min.css">

    <link rel="stylesheet" href="/assets/main.css">
    <link rel="canonical" href="http://kristianeschenburg.github.io/2019/03/delta-method">
    <link rel="alternate" type="application/rss+xml" title="A Rambling On"
        href="/feed.xml">

</head>

<body>

  <!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
        <a class="navbar-brand" href="/">A Rambling On</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
            data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
            aria-label="Toggle navigation">
            Menu
            <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">

                <!-- Home -->
                <li class="nav-item">
                    <a class="nav-link" href="/">Home</a>
                </li>
                
                <!-- Posts -->
                <li class="nav-item">
                    <a class="nav-link" href="/posts">Posts</a>
                </li>

                <!-- Code -->
                <li class="nav-item">
                    <a class="nav-link" href="/code">Code</a>
                </li>

                <!-- Resume -->
                <li class="nav-item">
                    <a class="nav-link" href="/resume">Resume</a>
                </li>

                <!-- About Me -->
                <li class="nav-item">
                    <a class="nav-link" href="/about">About</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

  <!-- Page Header -->

  <header class="masthead">
    
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="post-heading">
            <h1>The Delta Method</h1>
            
            <span class="meta">Posted by
              <a href="#">Kristian M. Eschenburg</a>
              on March 19, 2019 &middot; <span class="reading-time" title="Estimated read time">
    
     24 mins  read </span>
            </span>
          </div>
        </div>
      </div>
    </div>
  </header>

  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">

        <p>Here, we’ll look at various applications of the <a href="https://en.wikipedia.org/wiki/Delta_method">Delta Method</a>, especially in the context of variance stabilizing transformations, along with looking at the confidence intervals of estimates.</p>

<p>The Delta Method is used as a way to approximate the <a href="https://en.wikipedia.org/wiki/Standard_error">Standard Error</a> of transformations of random variables, and is based on a <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor Series</a> approximation.</p>

<p>In the univariate case, if we have a random variable, <script type="math/tex">X_{n}</script>, that converges in distribution to a <script type="math/tex">N(0, \sigma^{2})</script> distribution, we can apply a function to this random variable as:</p>

<script type="math/tex; mode=display">\begin{align}
\sqrt{n}(X_{n} - \theta) \xrightarrow{d} N(0,\sigma^{2}) \\
\sqrt{n}(g(X_{n}) - g(\theta)) \xrightarrow{d} \; ?
\end{align}</script>

<p>However, we don’t know the asymptotic variance of this transformed variable just yet.  In this case, we can approximate our function <script type="math/tex">g(x)</script> using a Taylor Series approximation, evaluated at <script type="math/tex">\theta</script>:</p>

<script type="math/tex; mode=display">\begin{align}
g(x) = g(\theta) + g\prime(\theta)(x-\theta) + O()
\end{align}</script>

<p>where <script type="math/tex">O()</script> is the remainder of higher-order Taylor Series terms that converges to 0.</p>

<p>By <a href="https://en.wikipedia.org/wiki/Slutsky%27s_theorem">Slutsky’s Theorem</a> and the <a href="https://en.wikipedia.org/wiki/Continuous_mapping_theorem">Continious Mapping Theorem</a>, we know that since <script type="math/tex">\bar{\theta} \xrightarrow{p} \theta</script>, we know that <script type="math/tex">g\prime(\bar{\theta}) \xrightarrow{p} g\prime(\theta)</script></p>

<p>Plugging this back in to our original equation and applying Slutsky’s Perturbation Theorem, we have:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
&= \sqrt{n}(\Big[g(\theta) + g\prime(\theta)(x-\theta)\Big] - g(\theta)) \\
&= \sqrt{n}(g\prime(\theta)(x-\theta)) \\
&= g\prime(\theta)\sqrt{n}(X_{n} - \theta)
\end{align} %]]></script>

<p>and since we know that <script type="math/tex">\sqrt{n}(\bar{X_{n}} - \theta)  \xrightarrow{d} N(0,\sigma^{2})</script>, we now know that <script type="math/tex">g\prime(\theta) \sqrt{n}(\bar{X_{n}} - \theta) \xrightarrow{d} N(0,g\prime(\theta)^{2} \sigma^{2})</script>.  As such, we have that:</p>

<script type="math/tex; mode=display">\begin{align}
\sqrt{n}(g(X_{n}) - g(\theta)) \xrightarrow{d} N(0, g\prime(\theta)^{2}\sigma^{2})
\end{align}</script>

<p>The Delta Method can be generalized to the multivariate case, where, instead of the derivative, we use the gradient vector of our function:</p>

<script type="math/tex; mode=display">\begin{align}
\sqrt{n}(g(\bar{X_{n}} - g(\theta)) \xrightarrow{d} N(0, \nabla(g)^{T} \Sigma \nabla(g))
\end{align}</script>

<p>Below, I’m going to look at a few examples applying the Delta Method to simple functions of random variables.  Then I’ll go into more involved examples applying the Delta Method via <a href="https://en.wikipedia.org/wiki/Variance-stabilizing_transformation">Variance Stabilizing Transformations</a>.  Oftentimes, the variance of an estimate depends on its mean, which can vary with the sample size.  In this case, we’d like to find a function <script type="math/tex">g(\theta)</script>, such that, when applied via the Delta Method, the variance is constant as a function of the sample size.</p>

<p>We’ll start by importing the necessary libraries and defining two functions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">rc</span>
<span class="n">rc</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="n">usetex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span><span class="p">,</span> <span class="n">poisson</span><span class="p">,</span> <span class="n">expon</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<p>Here, we define two simple functions – one to compute the difference between our estimate and its population paramter, and the other to compute the function of our random variable as described by the Central Limit Theorem.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conv_prob</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est</span><span class="p">,</span> <span class="n">pop</span><span class="p">):</span>
    
    <span class="s">"""
    Method to compute the estimate for convergence in probability.
    """</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">est</span><span class="o">-</span><span class="n">pop</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">clt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est</span><span class="p">,</span> <span class="n">pop</span><span class="p">):</span>
    
    <span class="s">"""
    Method to examine the Central Limit Theorem.
    """</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">est</span><span class="o">-</span><span class="n">pop</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s have a look at an easy example with the Normal Distribution.  We’ll set <script type="math/tex">\mu = 0</script> and <script type="math/tex">\sigma^{2} = 5</script>.  Remember that when using the <code class="highlighter-rouge">Scipy</code> Normal distribution, the <code class="highlighter-rouge">norm</code> class accepts the <strong>standard deviation</strong>, not the variance.  We’ll show via the Central Limit Theorem that the function <script type="math/tex">\sqrt{n}(\bar{X_{n}} - \mu) \xrightarrow{d} N(0,\sigma^{2})</script>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set sample sample sizes, and number of sampling iterations
</span><span class="n">N</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">iters</span> <span class="o">=</span> <span class="mi">500</span>

<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># store estimates
</span><span class="n">norm_clt</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">iters</span><span class="p">,</span><span class="mi">1000</span><span class="p">))</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
        
        <span class="n">est_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">])</span>
        <span class="n">norm_clt</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est_norm</span><span class="p">,</span> <span class="n">mu</span><span class="p">))</span>
</code></pre></div></div>

<p>Now let’s plot the results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot results using violin plots
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">norm_clt</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Sample Size: </span><span class="si">%</span><span class="s">i has empirical variance: </span><span class="si">%.2</span><span class="s">f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
        
    <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">norm_clt</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">],)</span>
</code></pre></div></div>

<figure>
    <img src="/img/delta_method/Normal_CLT.jpg" class="center-image" width="100%" />
    <figcaption>Central Limit Theorem applied to Normal Distribution.</figcaption>
</figure>

<p>As expected, we see that the Normal distribution mean and variance estimates are independent of the sample size.  In this case, we don’t need to apply a variance stabiliing transformation.  We also see that the variance fluctuates around <script type="math/tex">5</script>.  Now, let’s apply a simple function <script type="math/tex">g(\theta) = \theta^{2}</script> to our data.  So <script type="math/tex">g\prime(\theta) = 2\theta</script>, and the variance of our function becomes <script type="math/tex">g\prime(\mu)^{2}\sigma^{2} = (2\mu)^{2} \sigma^{2} = 4\mu^{2}\sigma^{2}</script>.  Let’s look at a few plots, as a function of changing <script type="math/tex">\mu</script>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set sample sample sizes, and number of sampling iterations
</span><span class="n">mus</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>

<span class="n">N</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">iters</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>


<span class="n">fig</span><span class="p">,</span> <span class="p">([</span><span class="n">ax1</span><span class="p">,</span><span class="n">ax2</span><span class="p">],</span> <span class="p">[</span><span class="n">ax3</span><span class="p">,</span><span class="n">ax4</span><span class="p">])</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">j</span> <span class="p">,</span><span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mus</span><span class="p">):</span>
    
    <span class="c1"># store estimates
</span>    <span class="n">norm_clt</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">iters</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
    
    
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>

            <span class="n">est_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">])</span>
            <span class="n">norm_clt</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est_norm</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">norm_clt</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">k</span><span class="p">],)</span>
</code></pre></div></div>

<figure>
    <img src="/img/delta_method/Normal_Squared.jpg" class="center-image" width="100%" />
    <figcaption>Central Limit Theorem applied to function of Normal Distribution.</figcaption>
</figure>

<p>We see that the variance increases as the mean increases, and that, as the sample sizes increase, the distributions converge to the <script type="math/tex">N(0, 4\mu^{2}\sigma^{2})</script> asymptotic distribution.</p>

<h4 id="variance-stabilization-for-the-poisson-distribution">Variance Stabilization for the Poisson Distribution</h4>

<p>Now let’s look at an example where the variance depends on the sample size.  We’ll use the Poisson distribution in this case.  We know that for the Poisson distribution, the variance is dependent on the mean, so let’s define a random variable, <script type="math/tex">X_{\lambda}</script>, where <script type="math/tex">\lambda = n*\theta</script>.  <script type="math/tex">n</script> is the sample size, and <script type="math/tex">\theta</script> is a fixed constant.</p>

<p>We’ll define <script type="math/tex">X_{\lambda } = \sum_{i=1}^{n} X_{\theta}</script>, the sum of <script type="math/tex">n</script> independent Poisson random variables, so that the expected value and variance of <script type="math/tex">X_{\lambda } = n\theta</script></p>

<p>If we wanted to apply the Central Limit Theorem to <script type="math/tex">X_{\lambda }</script>, our convergence would be as follows:</p>

<script type="math/tex; mode=display">\begin{align}
\sqrt{n}(X_{\lambda} - \lambda) \xrightarrow{d} N(0,\sigma^{2}(\lambda))
\end{align}</script>

<p>where the variance <script type="math/tex">\sigma^{2}(\lambda)</script> depends on the mean, <script type="math/tex">\lambda</script>.  In order to stabilize the variance of this variable, we can apply the <a href="https://en.wikipedia.org/wiki/Delta_method">Delta Method</a>, in order to generate a variable that converges to a standard Normal distribution asymptotically.</p>

<script type="math/tex; mode=display">\begin{align}
\sqrt{n}(g(X_{\lambda}) - g(\lambda)) \xrightarrow{d} N(0,g\prime(\theta)^{2}\sigma^{2}) \\
\end{align}</script>

<p>where</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
&g\prime(\theta)^{2} \theta = 1 \\
&g\prime(\theta)^{2} = \frac{1}{\theta} \\
&g\prime(\theta) = \frac{1}{\sqrt{\theta}} \\
&g(\theta) = \int \frac{\partial{\theta}}{\sqrt{\theta}} \\
&g(\theta) = 2\sqrt{\theta}
\end{align} %]]></script>

<p>is our variance stabilizing function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">p_lambda</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    
    <span class="s">"""
    Function to compute lambda parameter for Poisson distribution.
    Theta is constant.
    """</span>
    <span class="k">return</span> <span class="n">n</span><span class="o">*</span><span class="n">theta</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">theta</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">N</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">750</span><span class="p">,</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">iters</span> <span class="o">=</span> <span class="mi">500</span>

<span class="n">clt_pois</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>
<span class="n">pois_novar</span><span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>
<span class="n">pois_var</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
        <span class="n">est_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">poisson</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">))</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

        <span class="n">pois_novar</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est_mu</span><span class="p">,</span> <span class="n">p_lambda</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>
        <span class="n">pois_var</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">est_mu</span><span class="p">),</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p_lambda</span><span class="p">(</span><span class="n">n</span><span class="p">))))</span>
        
        <span class="n">clt_pois</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_prob</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est_mu</span><span class="p">,</span> <span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,([</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">])</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">pois_novar</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">pois_var</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</code></pre></div></div>

<figure>
    <img src="/img/delta_method/Poisson.jpg" class="center-image" width="100%" />
    <figcaption>Variance stabilization of Poisson distribution.</figcaption>
</figure>

<h4 id="variance-stabilization-for-the-exponential-distribution">Variance Stabilization for the Exponential Distribution</h4>

<p>Applying the same method to the Exponential distribtuion, we’ll find that the variance stabilizing transformation is <script type="math/tex">g(\theta) = log(\theta)</script>.  We’ll apply that here:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">theta</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">N</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">750</span><span class="p">,</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">iters</span> <span class="o">=</span> <span class="mi">500</span>

<span class="n">clt_exp</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>
<span class="n">exp_novar</span><span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>
<span class="n">exp_var</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">}</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">N</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
        <span class="n">samps</span> <span class="o">=</span> <span class="n">expon</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        
        <span class="n">est_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samps</span><span class="p">)</span>
        <span class="n">est_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samps</span><span class="p">)</span>

        <span class="n">exp_novar</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est_mu</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">)))</span>
        <span class="n">exp_var</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">est_mu</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">)))</span>
        
        <span class="n">clt_exp</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_prob</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">est_mu</span><span class="p">,</span> <span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,([</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">])</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">exp_novar</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">exp_var</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</code></pre></div></div>

<figure>
    <img src="/img/delta_method/Exponential.jpg" class="center-image" width="100%" />
    <figcaption>Variance stabilization of Exponential distribution.</figcaption>
</figure>

<h4 id="example-of-standard-error-computation-using-delta-method-for-polynomial-regression">Example of Standard Error Computation Using Delta Method for Polynomial Regression</h4>

<p>As an example of applying the Delta Method to a real-world dataset,  I’ve downloaded the <a href="https://archive.ics.uci.edu/ml/datasets/banknote+authentication"><strong>banknote</strong></a> dataset from the <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning Repository</a>.  In this exercise, I’ll apply the <a href="https://en.wikipedia.org/wiki/Logistic_function">logistic function</a> via logistic regression to assess whether or not a banknote is real or fake, using a set of features.   I’ll compute confidence intervals of our prediction probabilities using the Delta Method.  There are four unique predictors in this case: the <strong>variance</strong>, <strong>skew</strong>, <strong>kurtosis</strong>, and <strong>entropy</strong> of the Wavelet-transformed banknote image.  I’ll treat each of these predictors independently, using polynomial basis function of degree <script type="math/tex">3</script>.</p>

<p>In this example, we’re interested in the standard error of our probability estimate.  Our function is the Logistic Function, as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
g(\beta) &= \frac{1}{1+e^{-x^{T}\beta}} \\
&= \frac{e^{x^{T}\beta}}{1+e^{x^{T}\beta}}
\end{align} %]]></script>

<p>where the gradient of this multivariate function is:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\nabla g(\beta) &= \frac{\partial g}{\partial \beta} e^{x^{T}\beta}(1+e^{x^{T}\beta})^{-1} \\
&= x^{T}e^{x^{T}\beta}(1+e^{x^{T}\beta})^{-1} - x^{T}e^{x^{T}\beta}e^{x^{T}\beta} \\
&= x^{T}\Big(e^{x^{T}\beta}(1+e^{x^{T}\beta})^{-1} - e^{x^{T}\beta}e^{x^{T}\beta}\Big)(1+e^{x^{T}\beta})^{-2} \\
&= x^{T} \frac{e^{x^{T}\beta}}{(1+e^{x^{T}\beta})^{2}} \\
\nabla g(\beta) &= x^{T} g(\beta)(1-g(\beta))
\end{align} %]]></script>

<p>so that the final estimate of our confidence interval becomes</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
& \sim N(0,x^{T} g(\beta)(1-g(\beta)) \Sigma g(\beta)(1-g(\beta))x) \\
& \sim N(0, \nabla g(\beta)^{T} \Sigma \nabla g(\beta))
\end{align} %]]></script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">bank</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/Users/kristianeschenburg/Documents/Statistics/BankNote.txt'</span><span class="p">,</span>
                   <span class="n">sep</span><span class="o">=</span><span class="s">','</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">'variance'</span><span class="p">,</span> <span class="s">'skew'</span><span class="p">,</span> <span class="s">'kurtosis'</span><span class="p">,</span> <span class="s">'entropy'</span><span class="p">,</span><span class="s">'class'</span><span class="p">])</span>
<span class="n">bank</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">measure</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s">'variance'</span><span class="p">,</span> <span class="s">'kurtosis'</span><span class="p">,</span> <span class="s">'skew'</span><span class="p">,</span> <span class="s">'entropy'</span><span class="p">]):</span>

    <span class="n">predictor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">bank</span><span class="p">[</span><span class="n">measure</span><span class="p">])</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">bank</span><span class="p">[</span><span class="s">'class'</span><span class="p">])</span>
    
    <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">response</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># plot test set
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">predictor</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">predictor</span><span class="p">[</span><span class="o">~</span><span class="n">idx</span><span class="p">],</span> <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'{:} By Classification'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">measure</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Measure: {:}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">measure</span><span class="p">),</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s">'Fake'</span><span class="p">,</span><span class="s">'Real'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<figure>
    <img src="/img/delta_method/bank_notes.jpg" class="center-image" width="100%" />
    <figcaption>Bank note feature distributions, based on note class.</figcaption>
</figure>

<p>Based on the above plot, we can see that <strong>variance</strong>, <strong>skew</strong>, and <strong>kurtosis</strong> seem to be the most informative, while the <strong>entropy</strong> distributions do not seem to be that different based on bank note class.</p>

<p>Next, we fit a logistic regression model of note classification on note feature, with polynomial order of degree 3.  We then compute the standard errors of the transformed variance.  It was transformed using the <strong>logistic function</strong>, so we’ll need to compute the gradient of this function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">measure</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s">'variance'</span><span class="p">,</span> <span class="s">'kurtosis'</span><span class="p">,</span> <span class="s">'skew'</span><span class="p">,</span> <span class="s">'entropy'</span><span class="p">]):</span>

    <span class="c1"># Generate polynomial object to degree 
</span>    <span class="c1"># transform age to 4-degree basis function
</span>    <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">idx_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">bank</span><span class="p">[</span><span class="n">measure</span><span class="p">])</span>

    <span class="n">predictor</span> <span class="o">=</span> <span class="n">bank</span><span class="p">[</span><span class="n">measure</span><span class="p">][</span><span class="n">idx_order</span><span class="p">]</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">bank</span><span class="p">[</span><span class="s">'class'</span><span class="p">][</span><span class="n">idx_order</span><span class="p">]</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span>

    <span class="c1"># fit logit curve to curve
</span>    <span class="n">logit</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>
    
    <span class="n">test_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">min</span><span class="p">(</span><span class="n">predictor</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">predictor</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">test_features</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">test_features</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="c1"># predict on test set
</span>    <span class="n">class_prob</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>

    <span class="n">cov</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">cov_params</span><span class="p">()</span>
    <span class="n">yx</span> <span class="o">=</span> <span class="p">(</span><span class="n">class_prob</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">class_prob</span><span class="p">))[:,</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">test_features</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">yx</span><span class="p">,</span> <span class="n">cov</span><span class="p">),</span> <span class="n">yx</span><span class="o">.</span><span class="n">T</span><span class="p">)))</span>

    <span class="c1"># probability can't exceed 1, or be less than 0
</span>    <span class="n">upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">class_prob</span><span class="o">+</span><span class="mf">1.96</span><span class="o">*</span><span class="n">se</span><span class="p">))</span>
    <span class="n">lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">class_prob</span><span class="o">-</span><span class="mf">1.96</span><span class="o">*</span><span class="n">se</span><span class="p">))</span>

    <span class="c1"># plot test set
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_features</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">class_prob</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_features</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">upper</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_features</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">lower</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">r'P(isReal \Big| X)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'{:}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">measure</span><span class="p">),</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Probability'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<figure>
    <img src="/img/delta_method/bank_notes_CI.jpg" class="center-image" width="100%" />
    <figcaption>Confidence intervals for each feature, computed using Delta Method.</figcaption>
</figure>


        <hr>

        <div class="clearfix">

          
          <a class="btn btn-primary float-left" href="/2018/12/mahalanobis" data-toggle="tooltip" data-placement="top" title="Mahalanobis Distance: A Distributional Exploration of Brain Connectivity">&larr; Previous<span class="d-none d-md-inline">
              Post</span></a>
          
          
          <a class="btn btn-primary float-right" href="/2019/08/list-size" data-toggle="tooltip" data-placement="top" title="Quick Note: Initialize Python List With Prespecified Size">Next<span class="d-none d-md-inline">
              Post</span> &rarr;</a>
          

        </div>

      </div>
    </div>
  </div>


  <!-- Footer -->

<hr>

<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-md-10 mx-auto">
                <ul class="list-inline text-center">
                    
                    <li class="list-inline-item">
                        <a href="mailto:keschenb@uw.edu">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="far fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://twitter.com/keschh">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.linkedin.com/in/kristianeschenburg">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/kristianeschenburg">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Kristian M. Eschenburg 2019</p>
            </div>
        </div>
    </div>
</footer>

  
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<script src="/assets/vendor/jquery/jquery.min.js"></script>
<script src="/assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="/assets/vendor/startbootstrap-clean-blog/js/clean-blog.min.js"></script>

<script src="/assets/scripts.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>



</body>

</html>
